import contextlib
import mlx.core as mx
import mlx.nn as nn
from .models import cache as cache
from .prompt_utils import apply_chat_template as apply_chat_template
from .sample_utils import top_p_sampling as top_p_sampling
from .utils import StoppingCriteria as StoppingCriteria, apply_repetition_penalty as apply_repetition_penalty, load as load, prepare_inputs as prepare_inputs
from _typeshed import Incomplete
from dataclasses import dataclass
from transformers import PreTrainedTokenizer as PreTrainedTokenizer
from typing import Any, Generator

DEFAULT_MODEL_PATH: str
DEFAULT_IMAGE: Incomplete
DEFAULT_AUDIO: Incomplete
DEFAULT_PROMPT: str
DEFAULT_MAX_TOKENS: int
DEFAULT_TEMPERATURE: float
DEFAULT_TOP_P: float
DEFAULT_SEED: int
DEFAULT_QUANTIZED_KV_START: int

def parse_arguments(): ...

generation_stream: Incomplete

@contextlib.contextmanager
def wired_limit(model: nn.Module, streams: list[mx.Stream] | None = None): ...

@dataclass
class GenerationResult:
    text: str = ...
    token: int | None = ...
    logprobs: list[float] | None = ...
    prompt_tokens: int = ...
    generation_tokens: int = ...
    total_tokens: int = ...
    prompt_tps: float = ...
    generation_tps: float = ...
    peak_memory: float = ...

def generate_step(input_ids: mx.array, model: nn.Module, pixel_values, mask, *, max_tokens: int = 256, temperature: float = 0.0, repetition_penalty: float | None = None, repetition_context_size: int | None = 20, top_p: float = 1.0, logit_bias: dict[int, float] | None = None, prompt_cache: list[Any] | None = None, max_kv_size: int | None = None, kv_bits: int | None = None, kv_group_size: int = 64, quantized_kv_start: int = 0, **kwargs) -> Generator[tuple[mx.array, mx.array], None, None]: ...
def stream_generate(model: nn.Module, processor: PreTrainedTokenizer, prompt: str, image: str | list[str] = None, audio: str | list[str] = None, **kwargs) -> str | Generator[str, None, None]: ...
def generate(model: nn.Module, processor: PreTrainedTokenizer, prompt: str, image: str | list[str] = None, audio: str | list[str] = None, verbose: bool = False, **kwargs) -> GenerationResult: ...
def main() -> None: ...
