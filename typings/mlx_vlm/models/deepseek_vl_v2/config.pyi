from ..base import BaseModelConfig as BaseModelConfig
from dataclasses import dataclass

@dataclass
class TextConfig(BaseModelConfig):
    model_type: str = ...
    vocab_size: int = ...
    hidden_size: int = ...
    intermediate_size: int = ...
    moe_intermediate_size: int = ...
    num_hidden_layers: int = ...
    num_attention_heads: int = ...
    num_key_value_heads: int = ...
    n_shared_experts: int | None = ...
    n_routed_experts: int | None = ...
    routed_scaling_factor: float = ...
    kv_lora_rank: int = ...
    q_lora_rank: int = ...
    qk_rope_head_dim: int = ...
    v_head_dim: int = ...
    qk_nope_head_dim: int = ...
    topk_method: str = ...
    n_group: int | None = ...
    topk_group: int | None = ...
    num_experts_per_tok: int | None = ...
    moe_layer_freq: int = ...
    first_k_dense_replace: int = ...
    max_position_embeddings: int = ...
    rms_norm_eps: float = ...
    rope_theta: float = ...
    rope_traditional: bool = ...
    rope_scaling: dict = ...
    attention_bias: bool = ...
    scoring_func: str = ...
    attn_type: str = ...
    def __post_init__(self) -> None: ...

@dataclass
class VisionConfig(BaseModelConfig):
    model_type: str
    layers: int = ...
    width: int = ...
    intermediate_size: int = ...
    num_attention_heads: int = ...
    image_size: int = ...
    patch_size: int = ...
    num_channels: int = ...
    layer_norm_eps: float = ...
    mlp_ratio: float = ...
    cls: str = ...
    params: dict = ...

@dataclass
class MLPConfig(BaseModelConfig):
    width: int
    intermediate_size: int
    hidden_act: str = ...

@dataclass
class ProjectorConfig(BaseModelConfig):
    projector_type: str = ...
    input_dim: int = ...
    n_embed: int = ...
    depth: int = ...
    mlp_ratio: int = ...
    downsample_ratio: int = ...
    token_pooling: bool = ...

@dataclass
class ModelConfig(BaseModelConfig):
    text_config: TextConfig
    vision_config: VisionConfig
    projector_config: ProjectorConfig
    model_type: str
    ignore_index: int = ...
    image_token_index: int = ...
    vision_feature_select_strategy: str = ...
    select_layer: int = ...
    pad_id: int = ...
    num_image_tokens: int = ...
    vocab_size: int = ...
    tile_tag: str = ...
    global_view_pos: str = ...
    eos_token_id: list[int] | None = ...
    quantization: dict | None = ...
    @classmethod
    def from_dict(cls, params): ...

@dataclass
class Conversation:
    system: str
    roles: list[str]
    messages: list[list[str]]
    offset: int
    sep_style: int
    sep: str
    sep2: str
    version: str = ...

@dataclass
class VLChatProcessorOutput:
    sft_format: str
    input_ids: list[int]
    pixel_values: list
    num_image_tokens: list[int]
    image_grid_thw: list[list[int]]
    image_sizes: list[list[int]] | None = ...
    videos: list | None = ...
    aspect_ratio_ids: list[int] | None = ...
    aspect_ratio_mask: list[list[int]] | None = ...
    cross_attention_mask: list[list[list[int]]] | None = ...
    attention_mask: list[int] | None = ...
    labels: list[int] | None = ...

@dataclass
class BatchCollateOutput:
    input_ids: list
    labels: list
    attention_mask: list
    pixel_values: list
