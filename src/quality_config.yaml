# Quality Configuration for MLX VLM Check
# This file defines thresholds and patterns used to detect quality issues in model generation.

thresholds:
  # Repetition detection
  repetition_ratio: 0.8          # 80% of tokens must be same to flag
  min_text_length: 10            # Minimum text length to check
  min_token_count: 5             # Minimum tokens to analyze

  # Phrase repetition detection (n-grams)
  min_phrase_repetitions: 3      # Minimum phrase repetitions before flagging
  max_phrase_repetitions: 10     # Flag if phrase repeats this many times regardless
  phrase_coverage_threshold: 0.4 # Minimum coverage ratio to flag (40%)
  min_phrase_length: 4           # Minimum n-gram length to check for repetition

  # Hallucination detection
  min_pipes_for_table: 4         # Minimum pipe characters to detect table
  min_table_rows: 2              # Minimum rows to confirm table structure
  min_mc_answers: 3              # Minimum multiple choice answers to flag pattern
  substantial_text_length: 200   # Text length threshold for question detection

  # Formatting violations
  max_markdown_headers: 5        # Maximum markdown headers before flagging

  # Context ignorance detection (additional)
  min_context_term_length: 2     # Minimum length for context term extraction

  # Verbosity detection
  max_verbosity_tokens: 300      # Substantial length threshold
  min_meta_patterns: 2           # Minimum meta-commentary patterns
  min_section_headers: 3         # Minimum section headers

  # Bullet point detection
  # Note: Set high for cataloging prompts that request keyword lists
  max_bullets: 25                # Maximum allowed bullet points

  # Generic output detection
  min_text_length_for_generic: 20 # Minimum text length to analyze for genericity
  generic_filler_threshold: 0.15  # Filler ratio threshold (15%)
  min_specificity_indicators: 2   # Minimum indicators for non-generic content

  # Context ignorance detection
  min_key_terms_threshold: 3      # Minimum key terms needed to evaluate context usage
  min_missing_ratio: 0.75         # Minimum ratio of missing terms (75%)

  # Confidence thresholds for output analysis
  high_confidence_threshold: 0.7  # High confidence ratio
  medium_confidence_threshold: 0.4  # Medium confidence ratio

  # Output degeneration detection thresholds
  min_text_for_degeneration: 20   # Minimum text length to check for degeneration
  min_cutoff_word_length: 2       # Words <= this at end may be cutoff
  max_control_chars: 3            # Control chars threshold before flagging
  non_ascii_ratio_threshold: 0.3  # Threshold for encoding shift detection (30%)
  non_ascii_ratio_multiplier: 3   # Multiplier for tail vs head comparison
  max_url_length: 100             # URLs longer than this are suspicious
  min_precise_stats: 2            # Number of overly precise stats to flag

  # Cataloging utility thresholds
  min_useful_words: 5             # Minimum words for useful output
  short_output_words: 15          # Output considered "short"
  substantial_prose_words: 20     # Words needed for "substantial" prose
  max_caption_words: 15           # Max words for implicit caption detection
  min_useful_chars: 10            # Minimum chars for useful output
  severe_echo_threshold: 0.8      # Echo ratio triggering severe penalty
  moderate_echo_threshold: 0.5    # Echo ratio triggering moderate penalty
  low_grounding_threshold: 0.3    # Visual grounding considered low
  low_compliance_threshold: 0.5   # Task compliance considered low
  low_info_gain_threshold: 0.3    # Information gain considered low
  grade_a_threshold: 80.0         # Score for A grade
  grade_b_threshold: 65.0         # Score for B grade
  grade_c_threshold: 50.0         # Score for C grade
  grade_d_threshold: 35.0         # Score for D grade
  # Cataloging utility score composition (weights should sum to ~100)
  cataloging_weight_information_gain: 25.0
  cataloging_weight_compliance: 30.0
  cataloging_weight_grounding: 30.0
  cataloging_weight_length: 15.0
  # Cataloging utility penalties/factors
  severe_echo_penalty: 0.5
  moderate_echo_penalty: 0.8
  very_short_length_factor: 0.2
  short_length_factor: 0.6

  # Harness/integration issue detection thresholds
  # These detect mlx-vlm bugs or model integration issues (not model quality)
  min_bpe_artifact_count: 5       # Min BPE artifacts to flag encoding issue
  min_tokens_for_substantial: 10  # Tokens below this are suspicious
  min_words_for_filler_response: 15  # Words below this in filler response
  min_words_for_truncated: 5      # Words below this = truncated output
  min_prompt_tokens_for_ratio: 100  # Prompt tokens needed for ratio check
  min_output_tokens_for_ratio: 15   # Output tokens below this with large prompt
  min_output_ratio: 0.02          # Minimum output/prompt ratio (2%)
  long_prompt_tokens_threshold: 3000   # Prompt size where context-related failures become likely
  severe_prompt_tokens_threshold: 12000  # Extreme prompt size risk threshold
  prompt_title_max_chars: 120      # Max chars for metadata title hints in generated prompt
  prompt_description_max_chars: 420  # Max chars for metadata description hints
  prompt_keyword_max_items: 20     # Max keyword hints injected into generated prompt
  prompt_keyword_item_max_chars: 36  # Max chars per keyword hint in generated prompt
  min_text_for_leak_detection: 100  # Min text length for training leak detection

patterns:
  # Hallucination detection
  hallucination_question_indicators:
    - "what is"
    - "how many"
    - "based on the chart"
    - "calculate"
  
  hallucination_edu_keywords:
    - "grade level"
    - "students with adhd"
    - "test scores"
    - "homework"

  # Verbosity detection
  meta_commentary:
    - "the image depicts"
    - "the image shows"
    - "the photograph captures"
    - "this image features"
    - "in conclusion"
    - "### analysis"
    - "### conclusion"
    - "based on the image"

  # Generic output detection
  filler_words:
    - "appears to"
    - "seems to"
    - "looks like"
    - "might be"
    - "could be"
    - "some"
    - "several"
    - "various"
    - "many"
    - "few"
    - "very"
    - "quite"
    - "rather"
    - "somewhat"
    - "fairly"
    - "thing"
    - "stuff"
    - "item"
    - "object"

  # Confidence indicator detection (regex patterns)
  confidence_hedge_patterns:
    - "\\bappears to\\b"
    - "\\bseems to\\b"
    - "\\blooks like\\b"
    - "\\bmight be\\b"
    - "\\bcould be\\b"
    - "\\bpossibly\\b"
    - "\\bperhaps\\b"
    - "\\bprobably\\b"
    - "\\blikely\\b"
    - "\\bmaybe\\b"
    - "\\bi think\\b"
    - "\\bi believe\\b"
    - "\\bit's unclear\\b"
    - "\\buncertain\\b"

  confidence_definitive_patterns:
    - "\\bis a\\b"
    - "\\bare \\w+\\b"
    - "\\bshows\\b"
    - "\\bdepicts\\b"
    - "\\bfeatures\\b"
    - "\\bcontains\\b"
    - "\\bdefinitely\\b"
    - "\\bclearly\\b"
    - "\\bobviously\\b"

  # Task structure detection labels (regex fragments)
  task_caption_labels:
    - "caption"
    - "title"

  task_description_labels:
    - "description"
    - "details?"
    - "summary"

  task_keyword_labels:
    - "keywords?"
    - "tags?"

  # Visual grounding detection (regex patterns)
  visual_grounding_visual_patterns:
    - "\\b(building|house|shop|store|street|road|car|vehicle|person|people|pedestrian)\\b"
    - "\\b(sign|window|door|roof|wall|brick|stone|glass)\\b"
    - "\\b(tree|sky|cloud|hill|mountain|grass|flower)\\b"
    - "\\b(light|lamp|shadow|reflection|glow)\\b"
    - "\\b(wearing|standing|sitting|walking|driving)\\b"

  visual_grounding_spatial_patterns:
    - "\\b(left|right|center|middle|foreground|background)\\b"
    - "\\b(above|below|beside|behind|front|back)\\b"
    - "\\b(near|far|distant|close|adjacent)\\b"
    - "\\b(top|bottom|side|corner|edge)\\b"

  visual_grounding_color_patterns:
    - "\\b(red|blue|green|yellow|orange|purple|pink|brown|black|white|gray|grey)\\b"
    - "\\b(golden|silver|bronze|dark|light|bright|pale|vivid)\\b"
    - "\\b(warm|cool|muted|saturated)\\b"

  # Fabricated-detail heuristics
  fabrication_url_patterns:
    - "https?://[^\\s<>\"']+"

  fabrication_suspicious_url_keywords:
    - "example.com"
    - "placeholder"
    - "xxx"
    - "fake"

  fabrication_long_url_path_patterns:
    - "/[a-z0-9]{20,}/"

  fabrication_precise_stat_patterns:
    - "\\b(\\d{1,3}(?:,\\d{3})*\\.\\d{3,})\\s*%?"

  fabrication_future_year_patterns:
    - "\\b(20[3-9]\\d|2[1-9]\\d{2})\\b"

  fabrication_citation_patterns:
    - "\\(([A-Z][a-z]+(?:\\s+et\\s+al\\.?)?,?\\s*\\d{4})\\)"

  # Training-leak heuristics
  training_leak_instruction_header_patterns:
    - "\\n# INSTRUCTION\\b"

  training_leak_task_header_patterns:
    - "\\n## (Task|Question|Instructions?):"

  training_leak_write_prompt_patterns:
    - "\\nWrite a (?:short )?(?:story|essay|poem|code)"

  training_leak_user_turn_patterns:
    - "\\n(?:User|Human|Question):\\s*\\n"

  training_leak_code_example_patterns:
    - "\\n```\\w+\\n.*?def \\w+\\("

  training_leak_qa_pair_patterns:
    - "\\nQ:\\s*\\n.*?\\nA:\\s*\\n"

  # Refusal detection
  refusal_explicit:
    - "i cannot"
    - "i can't"
    - "i'm unable to"
    - "i am unable to"
    - "sorry, i can't"
    - "sorry, i cannot"
  
  refusal_uncertainty:
    - "it's unclear"
    - "it's difficult to say"
    - "i'm not sure"
    - "i cannot determine"
    - "unable to determine"
    - "difficult to tell"

  refusal_insufficient_info:
    - "not enough information"
    - "insufficient detail"
    - "cannot see clearly"
    - "too blurry"
    - "image quality"

  # Language mixing / Artifacts (Regex patterns)
  tokenizer_artifacts:
    - "<\\|endoftext\\|>"
    - "<\\|end\\|>"
    - "<s>"
    - "</s>"
    - "\\[SEP\\]"
    - "\\[CLS\\]"
    - "\\[PAD\\]"
    - "\\[UNK\\]"
    - "\\[MASK\\]"
    - "<pad>"
    - "<unk>"
    - "<mask>"

  code_patterns:
    - "\\bdef\\s+\\w+\\("           # Python function definition
    - "\\bfunction\\s+\\w+\\("      # JavaScript function
    - "\\bclass\\s+\\w+"            # Class definition
    - "\\bimport\\s+\\w+"           # Import statement
    - "\\breturn\\s+"               # Return statement
