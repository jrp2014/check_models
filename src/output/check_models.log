2025-11-09 22:31:53,856 - INFO - â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
2025-11-09 22:31:53,856 - WARNING - SECURITY WARNING: --trust-remote-code is enabled.
2025-11-09 22:31:53,856 - WARNING - This allows execution of remote code and may pose security risks.
2025-11-09 22:31:53,856 - INFO - ================================================================================
2025-11-09 22:31:53,856 - INFO - MLX Vision Language Model Check
2025-11-09 22:31:53,856 - INFO - ================================================================================
2025-11-09 22:31:53,856 - INFO - Scanning folder: /Users/jrp/Pictures/Processed
2025-11-09 22:31:53,856 - INFO - â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
2025-11-09 22:31:53,870 - INFO - Image File: /Users/jrp/Pictures/Processed/20251108-152957_DSC07340.jpg
2025-11-09 22:31:53,870 - INFO - â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
2025-11-09 22:31:53,876 - INFO - Image dimensions: 7720x5400 (41.7 MPixels)
2025-11-09 22:31:53,876 - INFO - Image Metadata
2025-11-09 22:31:53,876 - INFO - â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
2025-11-09 22:31:53,877 - INFO - Date: 2025-11-08 15:29:57 GMT
2025-11-09 22:31:53,877 - INFO - Description: , The Street, Chilham, England, United Kingdom, UK
A quiet late autumn afternoon on The Street in the quintessential English village of Chilham, Kent. The low November sun highlights the contrast between contemporary cars parked along the narrow lane and the row of beautifully preserved 15th-century half-timbered houses. With their steeply pitched tile roofs and prominent brick chimneys, these buildings create a scene that feels largely unchanged for centuries. This historic lane is part of a village known for its remarkable preservation, making it a popular filming location that offers a genuine glimpse into England's architectural past.
2025-11-09 22:31:53,877 - INFO - GPS Location: 
2025-11-09 22:31:53,877 - INFO - Prompt Configuration
2025-11-09 22:31:53,878 - INFO - â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
2025-11-09 22:31:53,878 - INFO - Generating default prompt based on image metadata.
2025-11-09 22:31:53,878 - INFO - Final prompt: Provide a factual caption, description, and keywords suitable for cataloguing, or searching for, the image. 

Context: The image relates to ', The Street, Chilham, England, United Kingdom, UK
A quiet ...
2025-11-09 22:31:53,878 - INFO - Loaded baseline text from: /Users/jrp/Documents/AI/mlx/scripts/src/output/baseline.txt
2025-11-09 22:31:53,878 - INFO - Processing specified models: mlx-community/Qwen2-VL-2B-Instruct-4bit
2025-11-09 22:31:53,878 - INFO - Processing 1 model(s)...
2025-11-09 22:31:53,878 - INFO - â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
2025-11-09 22:31:53,878 - INFO - Processing Model [1/1]: Qwen2-VL-2B-Instruct-4bit
2025-11-09 22:31:53,878 - INFO - â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
2025-11-09 22:31:53,878 - INFO - Processing '20251108-152957_DSC07340.jpg' with model: mlx-community/Qwen2-VL-2B-Instruct-4bit
2025-11-09 22:32:27,723 - ERROR - Failed to load model mlx-community/Qwen2-VL-2B-Instruct-4bit
Traceback (most recent call last):
  File "/Users/jrp/Documents/AI/mlx/scripts/src/check_models.py", line 3409, in _run_model_generation
    model, tokenizer = load(
                       ~~~~^
        path_or_hf_repo=params.model_identifier,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        lazy=params.lazy,
        ^^^^^^^^^^^^^^^^^
        trust_remote_code=params.trust_remote_code,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/jrp/Documents/AI/mlx/mlx-vlm/mlx_vlm/utils.py", line 305, in load
    processor = load_processor(model_path, True, eos_token_ids=eos_token_id, **kwargs)
  File "/Users/jrp/Documents/AI/mlx/mlx-vlm/mlx_vlm/utils.py", line 366, in load_processor
    processor = AutoProcessor.from_pretrained(model_path, **kwargs)
  File "/opt/homebrew/Caskroom/miniconda/base/lib/python3.13/site-packages/transformers/models/auto/processing_auto.py", line 396, in from_pretrained
    return processor_class.from_pretrained(
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        pretrained_model_name_or_path, trust_remote_code=trust_remote_code, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/opt/homebrew/Caskroom/miniconda/base/lib/python3.13/site-packages/transformers/processing_utils.py", line 1394, in from_pretrained
    args = cls._get_arguments_from_pretrained(pretrained_model_name_or_path, **kwargs)
  File "/opt/homebrew/Caskroom/miniconda/base/lib/python3.13/site-packages/transformers/processing_utils.py", line 1453, in _get_arguments_from_pretrained
    args.append(attribute_class.from_pretrained(pretrained_model_name_or_path, **kwargs))
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Caskroom/miniconda/base/lib/python3.13/site-packages/transformers/utils/import_utils.py", line 2157, in __getattribute__
    requires_backends(cls, cls._backends)
    ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Caskroom/miniconda/base/lib/python3.13/site-packages/transformers/utils/import_utils.py", line 2143, in requires_backends
    raise ImportError("".join(failed))
ImportError: 
AutoVideoProcessor requires the PyTorch library but it was not found in your environment. Check out the instructions on the
installation page: https://pytorch.org/get-started/locally/ and follow the ones that match your environment.
Please note that you may need to restart your runtime after installation.

AutoVideoProcessor requires the Torchvision library but it was not found in your environment. Check out the instructions on the
installation page: https://pytorch.org/get-started/locally/ and follow the ones that match your environment.
Please note that you may need to restart your runtime after installation.

2025-11-09 22:32:27,740 - ERROR - Model processing error
Traceback (most recent call last):
  File "/Users/jrp/Documents/AI/mlx/scripts/src/check_models.py", line 3409, in _run_model_generation
    model, tokenizer = load(
                       ~~~~^
        path_or_hf_repo=params.model_identifier,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        lazy=params.lazy,
        ^^^^^^^^^^^^^^^^^
        trust_remote_code=params.trust_remote_code,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/jrp/Documents/AI/mlx/mlx-vlm/mlx_vlm/utils.py", line 305, in load
    processor = load_processor(model_path, True, eos_token_ids=eos_token_id, **kwargs)
  File "/Users/jrp/Documents/AI/mlx/mlx-vlm/mlx_vlm/utils.py", line 366, in load_processor
    processor = AutoProcessor.from_pretrained(model_path, **kwargs)
  File "/opt/homebrew/Caskroom/miniconda/base/lib/python3.13/site-packages/transformers/models/auto/processing_auto.py", line 396, in from_pretrained
    return processor_class.from_pretrained(
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        pretrained_model_name_or_path, trust_remote_code=trust_remote_code, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/opt/homebrew/Caskroom/miniconda/base/lib/python3.13/site-packages/transformers/processing_utils.py", line 1394, in from_pretrained
    args = cls._get_arguments_from_pretrained(pretrained_model_name_or_path, **kwargs)
  File "/opt/homebrew/Caskroom/miniconda/base/lib/python3.13/site-packages/transformers/processing_utils.py", line 1453, in _get_arguments_from_pretrained
    args.append(attribute_class.from_pretrained(pretrained_model_name_or_path, **kwargs))
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Caskroom/miniconda/base/lib/python3.13/site-packages/transformers/utils/import_utils.py", line 2157, in __getattribute__
    requires_backends(cls, cls._backends)
    ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Caskroom/miniconda/base/lib/python3.13/site-packages/transformers/utils/import_utils.py", line 2143, in requires_backends
    raise ImportError("".join(failed))
ImportError: 
AutoVideoProcessor requires the PyTorch library but it was not found in your environment. Check out the instructions on the
installation page: https://pytorch.org/get-started/locally/ and follow the ones that match your environment.
Please note that you may need to restart your runtime after installation.

AutoVideoProcessor requires the Torchvision library but it was not found in your environment. Check out the instructions on the
installation page: https://pytorch.org/get-started/locally/ and follow the ones that match your environment.
Please note that you may need to restart your runtime after installation.


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/jrp/Documents/AI/mlx/scripts/src/check_models.py", line 3512, in process_image_with_model
    output: GenerationResult | SupportsGenerationResult = _run_model_generation(
                                                          ~~~~~~~~~~~~~~~~~~~~~^
        params=params,
        ^^^^^^^^^^^^^^
    )
    ^
  File "/Users/jrp/Documents/AI/mlx/scripts/src/check_models.py", line 3424, in _run_model_generation
    raise ValueError(error_details) from load_err
ValueError: Model loading failed: 
AutoVideoProcessor requires the PyTorch library but it was not found in your environment. Check out the instructions on the
installation page: https://pytorch.org/get-started/locally/ and follow the ones that match your environment.
Please note that you may need to restart your runtime after installation.

AutoVideoProcessor requires the Torchvision library but it was not found in your environment. Check out the instructions on the
installation page: https://pytorch.org/get-started/locally/ and follow the ones that match your environment.
Please note that you may need to restart your runtime after installation.

Traceback (most recent call last):
  File "/Users/jrp/Documents/AI/mlx/scripts/src/check_models.py", line 3409, in _run_model_generation
    model, tokenizer = load(
                       ~~~~^
        path_or_hf_repo=params.model_identifier,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        lazy=params.lazy,
        ^^^^^^^^^^^^^^^^^
        trust_remote_code=params.trust_remote_code,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/jrp/Documents/AI/mlx/mlx-vlm/mlx_vlm/utils.py", line 305, in load
    processor = load_processor(model_path, True, eos_token_ids=eos_token_id, **kwargs)
  File "/Users/jrp/Documents/AI/mlx/mlx-vlm/mlx_vlm/utils.py", line 366, in load_processor
    processor = AutoProcessor.from_pretrained(model_path, **kwargs)
  File "/opt/homebrew/Caskroom/miniconda/base/lib/python3.13/site-packages/transformers/models/auto/processing_auto.py", line 396, in from_pretrained
    return processor_class.from_pretrained(
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        pretrained_model_name_or_path, trust_remote_code=trust_remote_code, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/opt/homebrew/Caskroom/miniconda/base/lib/python3.13/site-packages/transformers/processing_utils.py", line 1394, in from_pretrained
    args = cls._get_arguments_from_pretrained(pretrained_model_name_or_path, **kwargs)
  File "/opt/homebrew/Caskroom/miniconda/base/lib/python3.13/site-packages/transformers/processing_utils.py", line 1453, in _get_arguments_from_pretrained
    args.append(attribute_class.from_pretrained(pretrained_model_name_or_path, **kwargs))
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Caskroom/miniconda/base/lib/python3.13/site-packages/transformers/utils/import_utils.py", line 2157, in __getattribute__
    requires_backends(cls, cls._backends)
    ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Caskroom/miniconda/base/lib/python3.13/site-packages/transformers/utils/import_utils.py", line 2143, in requires_backends
    raise ImportError("".join(failed))
ImportError: 
AutoVideoProcessor requires the PyTorch library but it was not found in your environment. Check out the instructions on the
installation page: https://pytorch.org/get-started/locally/ and follow the ones that match your environment.
Please note that you may need to restart your runtime after installation.

AutoVideoProcessor requires the Torchvision library but it was not found in your environment. Check out the instructions on the
installation page: https://pytorch.org/get-started/locally/ and follow the ones that match your environment.
Please note that you may need to restart your runtime after installation.


2025-11-09 22:32:27,743 - ERROR - [RUN 1/1] SUMMARY model=Qwen2-VL-2B-Instruct-4bit status=FAIL stage=processing
2025-11-09 22:32:27,743 - ERROR - error=Model loading failed: AutoVideoProcessorâ€¦
2025-11-09 22:32:27,743 - ERROR - âœ— FAILED: Qwen2-VL-2B-Instruct-4bit
2025-11-09 22:32:27,743 - ERROR - Stage:
2025-11-09 22:32:27,743 - ERROR -   processing
2025-11-09 22:32:27,743 - ERROR - Error:
2025-11-09 22:32:27,743 - ERROR -   Model loading failed:
2025-11-09 22:32:27,743 - ERROR -   AutoVideoProcessor requires the PyTorch library but it was not found in your
2025-11-09 22:32:27,743 - ERROR -   environment. Check out the instructions on the
2025-11-09 22:32:27,743 - ERROR -   installation page: https://pytorch.org/get-started/locally/ and follow the
2025-11-09 22:32:27,743 - ERROR -   ones that match your environment.
2025-11-09 22:32:27,743 - ERROR -   Please note that you may need to restart your runtime after installation.
2025-11-09 22:32:27,743 - ERROR -   AutoVideoProcessor requires the Torchvision library but it was not found in
2025-11-09 22:32:27,743 - ERROR -   your environment. Check out the instructions on the
2025-11-09 22:32:27,743 - ERROR -   installation page: https://pytorch.org/get-started/locally/ and follow the
2025-11-09 22:32:27,743 - ERROR -   ones that match your environment.
2025-11-09 22:32:27,743 - ERROR -   Please note that you may need to restart your runtime after installation.
2025-11-09 22:32:27,743 - ERROR -   Traceback (most recent call last):
2025-11-09 22:32:27,743 - ERROR -     File "/Users/jrp/Documents/AI/mlx/scripts/src/check_models.py", line 3409,
2025-11-09 22:32:27,743 - ERROR -   in _run_model_generation
2025-11-09 22:32:27,743 - ERROR -       model, tokenizer = load(
2025-11-09 22:32:27,743 - ERROR -                          ~~~~^
2025-11-09 22:32:27,743 - ERROR -           path_or_hf_repo=params.model_identifier,
2025-11-09 22:32:27,743 - ERROR -           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-09 22:32:27,743 - ERROR -           lazy=params.lazy,
2025-11-09 22:32:27,743 - ERROR -           ^^^^^^^^^^^^^^^^^
2025-11-09 22:32:27,743 - ERROR -           trust_remote_code=params.trust_remote_code,
2025-11-09 22:32:27,743 - ERROR -           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-09 22:32:27,743 - ERROR -       )
2025-11-09 22:32:27,743 - ERROR -       ^
2025-11-09 22:32:27,743 - ERROR -     File "/Users/jrp/Documents/AI/mlx/mlx-vlm/mlx_vlm/utils.py", line 305, in
2025-11-09 22:32:27,744 - ERROR -   load
2025-11-09 22:32:27,744 - ERROR -       processor = load_processor(model_path, True, eos_token_ids=eos_token_id,
2025-11-09 22:32:27,744 - ERROR -   **kwargs)
2025-11-09 22:32:27,744 - ERROR -     File "/Users/jrp/Documents/AI/mlx/mlx-vlm/mlx_vlm/utils.py", line 366, in
2025-11-09 22:32:27,744 - ERROR -   load_processor
2025-11-09 22:32:27,744 - ERROR -       processor = AutoProcessor.from_pretrained(model_path, **kwargs)
2025-11-09 22:32:27,744 - ERROR -     File
2025-11-09 22:32:27,744 - ERROR -   "/opt/homebrew/Caskroom/miniconda/base/lib/python3.13/site-packages/transformers/models/auto/processing_auto.py",
2025-11-09 22:32:27,744 - ERROR -   line 396, in from_pretrained
2025-11-09 22:32:27,744 - ERROR -       return processor_class.from_pretrained(
2025-11-09 22:32:27,744 - ERROR -              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
2025-11-09 22:32:27,744 - ERROR -           pretrained_model_name_or_path, trust_remote_code=trust_remote_code,
2025-11-09 22:32:27,744 - ERROR -   **kwargs
2025-11-09 22:32:27,744 - ERROR -   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-09 22:32:27,744 - ERROR -       )
2025-11-09 22:32:27,744 - ERROR -       ^
2025-11-09 22:32:27,744 - ERROR -     File
2025-11-09 22:32:27,744 - ERROR -   "/opt/homebrew/Caskroom/miniconda/base/lib/python3.13/site-packages/transformers/processing_utils.py",
2025-11-09 22:32:27,744 - ERROR -   line 1394, in from_pretrained
2025-11-09 22:32:27,744 - ERROR -       args = cls._get_arguments_from_pretrained(pretrained_model_name_or_path,
2025-11-09 22:32:27,744 - ERROR -   **kwargs)
2025-11-09 22:32:27,744 - ERROR -     File
2025-11-09 22:32:27,744 - ERROR -   "/opt/homebrew/Caskroom/miniconda/base/lib/python3.13/site-packages/transformers/processing_utils.py",
2025-11-09 22:32:27,744 - ERROR -   line 1453, in _get_arguments_from_pretrained
2025-11-09 22:32:27,744 - ERROR -       args.append(attribute_class.from_pretrained(pretrained_model_name_or_path,
2025-11-09 22:32:27,744 - ERROR -   **kwargs))
2025-11-09 22:32:27,744 - ERROR -                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-09 22:32:27,744 - ERROR -     File
2025-11-09 22:32:27,744 - ERROR -   "/opt/homebrew/Caskroom/miniconda/base/lib/python3.13/site-packages/transformers/utils/import_utils.py",
2025-11-09 22:32:27,744 - ERROR -   line 2157, in __getattribute__
2025-11-09 22:32:27,744 - ERROR -       requires_backends(cls, cls._backends)
2025-11-09 22:32:27,744 - ERROR -       ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^
2025-11-09 22:32:27,744 - ERROR -     File
2025-11-09 22:32:27,744 - ERROR -   "/opt/homebrew/Caskroom/miniconda/base/lib/python3.13/site-packages/transformers/utils/import_utils.py",
2025-11-09 22:32:27,744 - ERROR -   line 2143, in requires_backends
2025-11-09 22:32:27,744 - ERROR -       raise ImportError("".join(failed))
2025-11-09 22:32:27,744 - ERROR -   ImportError:
2025-11-09 22:32:27,744 - ERROR -   AutoVideoProcessor requires the PyTorch library but it was not found in your
2025-11-09 22:32:27,744 - ERROR -   environment. Check out the instructions on the
2025-11-09 22:32:27,744 - ERROR -   installation page: https://pytorch.org/get-started/locally/ and follow the
2025-11-09 22:32:27,744 - ERROR -   ones that match your environment.
2025-11-09 22:32:27,744 - ERROR -   Please note that you may need to restart your runtime after installation.
2025-11-09 22:32:27,744 - ERROR -   AutoVideoProcessor requires the Torchvision library but it was not found in
2025-11-09 22:32:27,744 - ERROR -   your environment. Check out the instructions on the
2025-11-09 22:32:27,744 - ERROR -   installation page: https://pytorch.org/get-started/locally/ and follow the
2025-11-09 22:32:27,744 - ERROR -   ones that match your environment.
2025-11-09 22:32:27,744 - ERROR -   Please note that you may need to restart your runtime after installation.
2025-11-09 22:32:27,744 - INFO - Performance Summary
2025-11-09 22:32:27,744 - INFO - â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
2025-11-09 22:32:27,744 - INFO - Model Name                | Generation (s) | Load (s) | Total (s) | Score (%) | Output                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     
2025-11-09 22:32:27,744 - INFO - ------------------------- | -------------- | -------- | --------- | --------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
2025-11-09 22:32:27,744 - INFO - Qwen2-VL-2B-Instruct-4bit |                |          |           |           | Error: processing - Model loading failed: 
AutoVideoProcessor requires the PyTorch library but it was not found in your environment. Check out the instructions on the
installation page: https://pytorch.org/get-started/locally/ and follow the ones that match your environment.
Please note that you may need to restart your runtime after installation.

AutoVideoProcessor requires the Torchvision library but it was not found in your environment. Check out the instructions on the
installation page: https://pytorch.org/get-started/locally/ and follow the ones that match your environment.
Please note that you may need to restart your runtime after installation.

Traceback (most recent call last):
  File "/Users/jrp/Documents/AI/mlx/scripts/src/check_models.py", line 3409, in _run_model_generation
    model, tokenizer = load(
                       ~~~~^
        path_or_hf_repo=params.model_identifier,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        lazy=params.lazy,
        ^^^^^^^^^^^^^^^^^
        trust_remote_code=params.trust_remote_code,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/jrp/Documents/AI/mlx/mlx-vlm/mlx_vlm/utils.py", line 305, in load
    processor = load_processor(model_path, True, eos_token_ids=eos_token_id, **kwargs)
  File "/Users/jrp/Documents/AI/mlx/mlx-vlm/mlx_vlm/utils.py", line 366, in load_processor
    processor = AutoProcessor.from_pretrained(model_path, **kwargs)
  File "/opt/homebrew/Caskroom/miniconda/base/lib/python3.13/site-packages/transformers/models/auto/processing_auto.py", line 396, in from_pretrained
    return processor_class.from_pretrained(
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        pretrained_model_name_or_path, trust_remote_code=trust_remote_code, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/opt/homebrew/Caskroom/miniconda/base/lib/python3.13/site-packages/transformers/processing_utils.py", line 1394, in from_pretrained
    args = cls._get_arguments_from_pretrained(pretrained_model_name_or_path, **kwargs)
  File "/opt/homebrew/Caskroom/miniconda/base/lib/python3.13/site-packages/transformers/processing_utils.py", line 1453, in _get_arguments_from_pretrained
    args.append(attribute_class.from_pretrained(pretrained_model_name_or_path, **kwargs))
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Caskroom/miniconda/base/lib/python3.13/site-packages/transformers/utils/import_utils.py", line 2157, in __getattribute__
    requires_backends(cls, cls._backends)
    ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Caskroom/miniconda/base/lib/python3.13/site-packages/transformers/utils/import_utils.py", line 2143, in requires_backends
    raise ImportError("".join(failed))
ImportError: 
AutoVideoProcessor requires the PyTorch library but it was not found in your environment. Check out the instructions on the
installation page: https://pytorch.org/get-started/locally/ and follow the ones that match your environment.
Please note that you may need to restart your runtime after installation.

AutoVideoProcessor requires the Torchvision library but it was not found in your environment. Check out the instructions on the
installation page: https://pytorch.org/get-started/locally/ and follow the ones that match your environment.
Please note that you may need to restart your runtime after installation.


2025-11-09 22:32:27,744 - INFO - 
================================================================================
FAILURE SUMMARY - Models Grouped by Root Cause
================================================================================

ValueError: Model loading failed:
  Affected models (1):
    â€¢ Qwen2-VL-2B-Instruct-4bit

================================================================================

2025-11-09 22:32:27,744 - INFO - 
2025-11-09 22:32:27,744 - INFO - - **Failed models:** 1
2025-11-09 22:32:27,744 - INFO - 
2025-11-09 22:32:27,745 - INFO - Report Generation
2025-11-09 22:32:27,745 - INFO - â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
2025-11-09 22:32:27,899 - INFO - HTML report saved to: /Users/jrp/Documents/AI/mlx/scripts/src/output/results.html
2025-11-09 22:32:28,105 - INFO - Markdown report saved to: /Users/jrp/Documents/AI/mlx/scripts/src/output/results.md
2025-11-09 22:32:28,105 - INFO - 
2025-11-09 22:32:28,105 - INFO - ğŸ“Š Reports successfully generated:
2025-11-09 22:32:28,105 - INFO -    HTML:     /Users/jrp/Documents/AI/mlx/scripts/src/output/results.html
2025-11-09 22:32:28,105 - INFO -    Markdown: /Users/jrp/Documents/AI/mlx/scripts/src/output/results.md
2025-11-09 22:32:28,105 - INFO -    Log:      /Users/jrp/Documents/AI/mlx/scripts/src/output/check_models.log
2025-11-09 22:32:28,106 - INFO - Execution Summary
2025-11-09 22:32:28,106 - INFO - â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
2025-11-09 22:32:28,106 - INFO - 
2025-11-09 22:32:28,106 - INFO - â±  Overall runtime: 34.62s
2025-11-09 22:32:28,106 - INFO - --- Library Versions ---
2025-11-09 22:32:28,106 - INFO - Pillow          : 12.0.0
2025-11-09 22:32:28,106 - INFO - huggingface-hub : 0.36.0
2025-11-09 22:32:28,106 - INFO - mlx             : 0.29.4.dev20251109+eba6a9d1
2025-11-09 22:32:28,106 - INFO - mlx-lm          : 0.28.4
2025-11-09 22:32:28,106 - INFO - mlx-vlm         : 0.3.5
2025-11-09 22:32:28,106 - INFO - tokenizers      : 0.22.1
2025-11-09 22:32:28,106 - INFO - transformers    : 4.57.1
2025-11-09 22:32:28,106 - INFO - Generated: 2025-11-09 22:32:28 GMT
2025-11-09 22:32:28,339 - INFO - 
2025-11-09 22:32:28,340 - INFO - --- System Information ---
2025-11-09 22:32:28,340 - INFO - OS                  : Darwin 25.1.0
2025-11-09 22:32:28,340 - INFO - macOS Version       : 26.1
2025-11-09 22:32:28,340 - INFO - SDK Version         : 26.1
2025-11-09 22:32:28,340 - INFO - Python Version      : 3.13.5
2025-11-09 22:32:28,340 - INFO - Architecture        : arm64
2025-11-09 22:32:28,340 - INFO - GPU/Chip            : Apple M4 Max
2025-11-09 22:32:28,340 - INFO - GPU Cores           : 40
2025-11-09 22:32:28,340 - INFO - Metal Support       : Metal 4
2025-11-09 22:32:28,340 - INFO - RAM                 : 128.0 GB
2025-11-09 22:32:28,340 - INFO - CPU Cores (Physical): 16
2025-11-09 22:32:28,340 - INFO - CPU Cores (Logical) : 16
