{
  "environment": {
    "library_versions": {
      "Pillow": "12.1.1",
      "huggingface-hub": "1.4.1",
      "mlx": "0.30.7.dev20260215+43f4a748",
      "mlx-lm": "0.30.7",
      "mlx-metal": null,
      "mlx-vlm": "0.3.12",
      "numpy": "2.4.2",
      "tokenizers": "0.22.2",
      "transformers": "5.1.0"
    },
    "platform": "macOS-26.3-arm64-arm-64bit-Mach-O",
    "preflight_issues": [
      "mlx-vlm load_image() has an unguarded URL startswith() branch; Path/BytesIO inputs can raise AttributeError in upstream code.",
      "transformers import utils no longer reference TRANSFORMERS_NO_TF/FLAX/JAX; check_models backend guard env vars may be ignored with this version."
    ],
    "system_info": {
      "Architecture": "arm64",
      "CPU Cores (Logical)": "16",
      "CPU Cores (Physical)": "16",
      "GPU Cores": "40",
      "GPU/Chip": "Apple M4 Max",
      "Metal SDK": "MacOSX.sdk",
      "Metal Support": "Metal 4",
      "OS": "Darwin 25.3.0",
      "Python Version": "3.13.9",
      "RAM": "128.0 GB",
      "SDK Version": "26.2",
      "Xcode Build": "17C52",
      "Xcode Version": "26.2",
      "macOS Version": "26.3"
    }
  },
  "failure": {
    "captured_output": "=== STDERR ===\nDownloading (incomplete total...): 0.00B [00:00, ?B/s]\n\rFetching 10 files:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\rFetching 10 files: 100%|##########| 10/10 [00:00<00:00, 13473.51it/s]\n\rDownload complete: : 0.00B [00:00, ?B/s]              \rDownload complete: : 0.00B [00:00, ?B/s]\n<unknown>:515: SyntaxWarning: invalid escape sequence '\\d'",
    "code": "MLX_VLM_MODEL_LOAD_MODEL",
    "message": "Model loading failed: RobertaTokenizer has no attribute additional_special_tokens",
    "package": "mlx-vlm",
    "phase": "model_load",
    "signature": "MLX_VLM_MODEL_LOAD_MODEL:2100d402a936",
    "stage": "Model Error",
    "traceback": "Traceback (most recent call last):\n  File \"/Users/jrp/Documents/AI/mlx/check_models/src/check_models.py\", line 9085, in _run_model_generation\n    model, processor, config = _load_model(params)\n                               ~~~~~~~~~~~^^^^^^^^\n  File \"/Users/jrp/Documents/AI/mlx/check_models/src/check_models.py\", line 8862, in _load_model\n    model, processor = load(\n                       ~~~~^\n        path_or_hf_repo=params.model_identifier,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<3 lines>...\n        trust_remote_code=params.trust_remote_code,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/Users/jrp/Documents/AI/mlx/mlx-vlm/mlx_vlm/utils.py\", line 405, in load\n    processor = load_processor(model_path, True, eos_token_ids=eos_token_id, **kwargs)\n  File \"/Users/jrp/Documents/AI/mlx/mlx-vlm/mlx_vlm/utils.py\", line 478, in load_processor\n    processor = AutoProcessor.from_pretrained(model_path, use_fast=True, **kwargs)\n  File \"/Users/jrp/Documents/AI/mlx/mlx-vlm/mlx_vlm/models/molmo/processing_molmo.py\", line 758, in _patched_auto_processor_from_pretrained\n    return _original_auto_processor_from_pretrained.__func__(\n           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n        cls, pretrained_model_name_or_path, **kwargs\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/Users/jrp/Documents/AI/mlx/mlx-vlm/mlx_vlm/models/base.py\", line 355, in _patched_auto_processor_from_pretrained\n    return previous_from_pretrained.__func__(\n           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n        cls, pretrained_model_name_or_path, **kwargs\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/Users/jrp/Documents/AI/mlx/mlx-vlm/mlx_vlm/models/phi3_v/processing_phi3_v.py\", line 699, in _patched_auto_processor_from_pretrained\n    return _original_auto_processor_from_pretrained.__func__(\n           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n        cls, pretrained_model_name_or_path, **kwargs\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/Users/jrp/Documents/AI/mlx/mlx-vlm/mlx_vlm/models/kimi_vl/processing_kimi_vl.py\", line 595, in _patched_auto_processor_from_pretrained\n    return _original_auto_processor_from_pretrained.__func__(\n           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n        cls, pretrained_model_name_or_path, **kwargs\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/opt/homebrew/Caskroom/miniconda/base/envs/mlx-vlm/lib/python3.13/site-packages/transformers/models/auto/processing_auto.py\", line 394, in from_pretrained\n    return processor_class.from_pretrained(\n           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n        pretrained_model_name_or_path, trust_remote_code=trust_remote_code, **kwargs\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/opt/homebrew/Caskroom/miniconda/base/envs/mlx-vlm/lib/python3.13/site-packages/transformers/processing_utils.py\", line 1403, in from_pretrained\n    return cls.from_args_and_dict(args, processor_dict, **instantiation_kwargs)\n           ~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/homebrew/Caskroom/miniconda/base/envs/mlx-vlm/lib/python3.13/site-packages/transformers/processing_utils.py\", line 1170, in from_args_and_dict\n    processor = cls(*args, **valid_kwargs)\n  File \"/Users/jrp/.cache/huggingface/modules/transformers_modules/microsoft/Florence_hyphen_2_hyphen_large_hyphen_ft/4a12a2b54b7016a48a22037fbd62da90cd566f2a/processing_florence2.py\", line 87, in __init__\n    tokenizer.additional_special_tokens + \\\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/homebrew/Caskroom/miniconda/base/envs/mlx-vlm/lib/python3.13/site-packages/transformers/tokenization_utils_base.py\", line 1291, in __getattr__\n    raise AttributeError(f\"{self.__class__.__name__} has no attribute {key}\")\nAttributeError: RobertaTokenizer has no attribute additional_special_tokens. Did you mean: 'add_special_tokens'?\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/Users/jrp/Documents/AI/mlx/check_models/src/check_models.py\", line 9277, in process_image_with_model\n    output: GenerationResult | SupportsGenerationResult = _run_model_generation(\n                                                          ~~~~~~~~~~~~~~~~~~~~~^\n        params=params,\n        ^^^^^^^^^^^^^^\n        phase_callback=_update_phase,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/Users/jrp/Documents/AI/mlx/check_models/src/check_models.py\", line 9093, in _run_model_generation\n    raise _tag_exception_failure_phase(ValueError(error_details), \"model_load\") from load_err\nValueError: Model loading failed: RobertaTokenizer has no attribute additional_special_tokens\n",
    "type": "ValueError"
  },
  "generated_at_utc": "2026-02-15T21:05:42+00:00",
  "model": "prince-canuma/Florence-2-large-ft",
  "repro": {
    "args": {
      "_check_models_preflight_issues": [
        "mlx-vlm load_image() has an unguarded URL startswith() branch; Path/BytesIO inputs can raise AttributeError in upstream code.",
        "transformers import utils no longer reference TRANSFORMERS_NO_TF/FLAX/JAX; check_models backend guard env vars may be ignored with this version."
      ],
      "adapter_path": null,
      "context_marker": "Context:",
      "detailed_metrics": false,
      "dry_run": false,
      "exclude": null,
      "folder": "/Users/jrp/Pictures/Processed",
      "force_color": false,
      "image": null,
      "kv_bits": null,
      "kv_group_size": 64,
      "lazy_load": false,
      "max_kv_size": null,
      "max_tokens": 500,
      "models": null,
      "no_color": false,
      "output_diagnostics": "/Users/jrp/Documents/AI/mlx/check_models/src/output/diagnostics.md",
      "output_env": "/Users/jrp/Documents/AI/mlx/check_models/src/output/environment.log",
      "output_html": "/Users/jrp/Documents/AI/mlx/check_models/src/output/results.html",
      "output_jsonl": "/Users/jrp/Documents/AI/mlx/check_models/src/output/results.jsonl",
      "output_log": "/Users/jrp/Documents/AI/mlx/check_models/src/output/check_models.log",
      "output_markdown": "/Users/jrp/Documents/AI/mlx/check_models/src/output/results.md",
      "output_tsv": "/Users/jrp/Documents/AI/mlx/check_models/src/output/results.tsv",
      "prefill_step_size": null,
      "prompt": null,
      "quality_config": null,
      "quantized_kv_start": 0,
      "repetition_context_size": 20,
      "repetition_penalty": null,
      "revision": null,
      "temperature": 0.0,
      "timeout": 300.0,
      "top_p": 1.0,
      "trust_remote_code": true,
      "verbose": true,
      "width": null
    },
    "env_vars": {
      "TOKENIZERS_PARALLELISM": "false",
      "TRANSFORMERS_NO_FLAX": "1",
      "TRANSFORMERS_NO_JAX": "1",
      "TRANSFORMERS_NO_TF": "1"
    },
    "image_path": "/Users/jrp/Pictures/Processed/20260214-154920_DSC09221.jpg",
    "image_ref_sha256": "e1f13b7b9f808a4015d713d2eecc5289af397b1d7854a59993dcce8f55445722",
    "image_sha256": "c473430b4df6535edc13d5750eaf48fe993d190e76207021e125e83742388bc9",
    "prompt_hash_sha256": "52f0f4e945354b03c9e7a9c5f8a1991e375341c12d514750fd85bef12c23c5a5",
    "prompt_preview": "Analyze this image for cataloguing metadata.\n\nReturn exactly these three sections:\n\nTitle: 6-12 words, descriptive and concrete.\n\nDescription: 1-2 factual sentences covering key subjects, setting, and action.\n\nKeywords: 15-30 comma-separated terms, ordered most specific to most general.\nUse concise, image-grounded wording and avoid speculation.\n\nContext: Existing metadata hints (use only if visual...",
    "rerun_command": "python -m check_models --image /Users/jrp/Pictures/Processed/20260214-154920_DSC09221.jpg --trust-remote-code --max-tokens 500 --temperature 0.0 --top-p 1.0 --repetition-context-size 20 --timeout 300.0 --verbose --models prince-canuma/Florence-2-large-ft",
    "seed": null
  },
  "schema_version": "1.0"
}
