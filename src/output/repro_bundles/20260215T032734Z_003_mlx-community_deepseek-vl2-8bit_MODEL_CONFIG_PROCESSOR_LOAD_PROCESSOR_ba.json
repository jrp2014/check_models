{
  "environment": {
    "library_versions": {
      "Pillow": "12.1.1",
      "huggingface-hub": "1.4.1",
      "mlx": "0.30.7.dev20260215+c184262d",
      "mlx-lm": "0.30.7",
      "mlx-metal": null,
      "mlx-vlm": "0.3.12",
      "numpy": "2.4.2",
      "tokenizers": "0.22.2",
      "transformers": "5.1.0"
    },
    "platform": "macOS-26.3-arm64-arm-64bit-Mach-O",
    "preflight_issues": [
      "mlx-vlm load_image() has an unguarded URL startswith() branch; Path/BytesIO inputs can raise AttributeError in upstream code.",
      "transformers import utils no longer reference TRANSFORMERS_NO_TF/FLAX/JAX; check_models backend guard env vars may be ignored with this version."
    ],
    "system_info": {
      "Architecture": "arm64",
      "CPU Cores (Logical)": "16",
      "CPU Cores (Physical)": "16",
      "GPU Cores": "40",
      "GPU/Chip": "Apple M4 Max",
      "Metal SDK": "MacOSX.sdk",
      "Metal Support": "Metal 4",
      "OS": "Darwin 25.3.0",
      "Python Version": "3.13.9",
      "RAM": "128.0 GB",
      "SDK Version": "26.2",
      "Xcode Build": "17C52",
      "Xcode Version": "26.2",
      "macOS Version": "26.3"
    }
  },
  "failure": {
    "captured_output": "=== STDOUT ===\nAdd pad token = ['<\uff5c\u2581pad\u2581\uff5c>'] to the tokenizer\n<\uff5c\u2581pad\u2581\uff5c>:2\nAdd image token = ['<image>'] to the tokenizer\n<image>:128815\nAdded grounding-related tokens\nAdded chat tokens\n\n=== STDERR ===\nDownloading (incomplete total...): 0.00B [00:00, ?B/s]\n\rFetching 13 files:   0%|          | 0/13 [00:00<?, ?it/s]\u001b[A\rFetching 13 files: 100%|##########| 13/13 [00:00<00:00, 15150.31it/s]\n\rDownload complete: : 0.00B [00:00, ?B/s]              \rDownload complete: : 0.00B [00:00, ?B/s]",
    "code": "MODEL_CONFIG_PROCESSOR_LOAD_PROCESSOR",
    "message": "Model preflight failed for mlx-community/deepseek-vl2-8bit: Loaded processor has no image_processor; expected multimodal processor.",
    "package": "model-config",
    "phase": "processor_load",
    "signature": "MODEL_CONFIG_PROCESSOR_LOAD_PROCESSOR:ba801e92890f",
    "stage": "Processor Error",
    "traceback": "Traceback (most recent call last):\n  File \"/Users/jrp/Documents/AI/mlx/check_models/src/check_models.py\", line 9040, in _run_model_generation\n    _run_model_preflight_validators(\n    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n        model_identifier=params.model_identifier,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<2 lines>...\n        phase_callback=phase_callback,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/Users/jrp/Documents/AI/mlx/check_models/src/check_models.py\", line 8965, in _run_model_preflight_validators\n    _raise_preflight_error(\n    ~~~~~~~~~~~~~~~~~~~~~~^\n        \"Loaded processor has no image_processor; expected multimodal processor.\",\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n        phase=\"processor_load\",\n        ^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/Users/jrp/Documents/AI/mlx/check_models/src/check_models.py\", line 8879, in _raise_preflight_error\n    raise _tag_exception_failure_phase(ValueError(message), phase)\nValueError: Loaded processor has no image_processor; expected multimodal processor.\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/Users/jrp/Documents/AI/mlx/check_models/src/check_models.py\", line 9221, in process_image_with_model\n    output: GenerationResult | SupportsGenerationResult = _run_model_generation(\n                                                          ~~~~~~~~~~~~~~~~~~~~~^\n        params=params,\n        ^^^^^^^^^^^^^^\n        phase_callback=_update_phase,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/Users/jrp/Documents/AI/mlx/check_models/src/check_models.py\", line 9052, in _run_model_generation\n    raise _tag_exception_failure_phase(ValueError(message), phase) from preflight_err\nValueError: Model preflight failed for mlx-community/deepseek-vl2-8bit: Loaded processor has no image_processor; expected multimodal processor.\n",
    "type": "ValueError"
  },
  "generated_at_utc": "2026-02-15T03:27:34+00:00",
  "model": "mlx-community/deepseek-vl2-8bit",
  "repro": {
    "args": {
      "_check_models_preflight_issues": [
        "mlx-vlm load_image() has an unguarded URL startswith() branch; Path/BytesIO inputs can raise AttributeError in upstream code.",
        "transformers import utils no longer reference TRANSFORMERS_NO_TF/FLAX/JAX; check_models backend guard env vars may be ignored with this version."
      ],
      "adapter_path": null,
      "context_marker": "Context:",
      "detailed_metrics": false,
      "dry_run": false,
      "exclude": null,
      "folder": "/Users/jrp/Pictures/Processed",
      "force_color": false,
      "image": null,
      "kv_bits": null,
      "kv_group_size": 64,
      "lazy_load": false,
      "max_kv_size": null,
      "max_tokens": 500,
      "models": null,
      "no_color": false,
      "output_diagnostics": "/Users/jrp/Documents/AI/mlx/check_models/src/output/diagnostics.md",
      "output_env": "/Users/jrp/Documents/AI/mlx/check_models/src/output/environment.log",
      "output_html": "/Users/jrp/Documents/AI/mlx/check_models/src/output/results.html",
      "output_jsonl": "/Users/jrp/Documents/AI/mlx/check_models/src/output/results.jsonl",
      "output_log": "/Users/jrp/Documents/AI/mlx/check_models/src/output/check_models.log",
      "output_markdown": "/Users/jrp/Documents/AI/mlx/check_models/src/output/results.md",
      "output_tsv": "/Users/jrp/Documents/AI/mlx/check_models/src/output/results.tsv",
      "prefill_step_size": null,
      "prompt": null,
      "quality_config": null,
      "quantized_kv_start": 0,
      "repetition_context_size": 20,
      "repetition_penalty": null,
      "revision": null,
      "temperature": 0.0,
      "timeout": 300.0,
      "top_p": 1.0,
      "trust_remote_code": true,
      "verbose": true,
      "width": null
    },
    "env_vars": {
      "TOKENIZERS_PARALLELISM": "false",
      "TRANSFORMERS_NO_FLAX": "1",
      "TRANSFORMERS_NO_JAX": "1",
      "TRANSFORMERS_NO_TF": "1"
    },
    "image_path": "/Users/jrp/Pictures/Processed/20260214-154920_DSC09221.jpg",
    "image_ref_sha256": "e1f13b7b9f808a4015d713d2eecc5289af397b1d7854a59993dcce8f55445722",
    "image_sha256": "c473430b4df6535edc13d5750eaf48fe993d190e76207021e125e83742388bc9",
    "prompt_hash_sha256": "52f0f4e945354b03c9e7a9c5f8a1991e375341c12d514750fd85bef12c23c5a5",
    "prompt_preview": "Analyze this image for cataloguing metadata.\n\nReturn exactly these three sections:\n\nTitle: 6-12 words, descriptive and concrete.\n\nDescription: 1-2 factual sentences covering key subjects, setting, and action.\n\nKeywords: 15-30 comma-separated terms, ordered most specific to most general.\nUse concise, image-grounded wording and avoid speculation.\n\nContext: Existing metadata hints (use only if visual...",
    "rerun_command": "python -m check_models --image /Users/jrp/Pictures/Processed/20260214-154920_DSC09221.jpg --trust-remote-code --max-tokens 500 --temperature 0.0 --top-p 1.0 --repetition-context-size 20 --timeout 300.0 --verbose --models mlx-community/deepseek-vl2-8bit",
    "seed": null
  },
  "schema_version": "1.0"
}
