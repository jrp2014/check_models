{"model": "HuggingFaceTB/SmolVLM-Instruct", "success": true, "error_stage": null, "error_message": null, "quality_issues": null, "metrics": {"prompt_tokens": 1430, "generation_tokens": 9, "generation_tps": 130.27194267080938, "peak_memory_gb": 5.54614324}}
{"model": "meta-llama/Llama-3.2-11B-Vision-Instruct", "success": true, "error_stage": null, "error_message": null, "quality_issues": "bullets(70)", "metrics": {"prompt_tokens": 237, "generation_tokens": 500, "generation_tps": 3.8978859703375575, "peak_memory_gb": 25.226043206}}
{"model": "microsoft/Florence-2-large-ft", "success": false, "error_stage": "Model Error", "error_message": "Model loading failed: Missing 1 parameters: \nlanguage_model.lm_head.weight.", "quality_issues": null, "metrics": {}}
{"model": "microsoft/Phi-3.5-vision-instruct", "success": true, "error_stage": null, "error_message": null, "quality_issues": "lang_mixing", "metrics": {"prompt_tokens": 1042, "generation_tokens": 500, "generation_tps": 11.164388804555971, "peak_memory_gb": 11.505708192}}
{"model": "mlx-community/Apriel-1.5-15b-Thinker-6bit-MLX", "success": true, "error_stage": null, "error_message": null, "quality_issues": "hallucination", "metrics": {"prompt_tokens": 2933, "generation_tokens": 500, "generation_tps": 35.92074188968386, "peak_memory_gb": 14.714749122}}
{"model": "mlx-community/Idefics3-8B-Llama3-bf16", "success": true, "error_stage": null, "error_message": null, "quality_issues": "formatting, context-ignored", "metrics": {"prompt_tokens": 2547, "generation_tokens": 246, "generation_tps": 29.287018255341717, "peak_memory_gb": 18.591584978}}
{"model": "mlx-community/InternVL3-14B-8bit", "success": true, "error_stage": null, "error_message": null, "quality_issues": "bullets(19)", "metrics": {"prompt_tokens": 2032, "generation_tokens": 279, "generation_tps": 28.667455861697654, "peak_memory_gb": 17.922640106}}
{"model": "mlx-community/Kimi-VL-A3B-Thinking-2506-bf16", "success": false, "error_stage": "Lib Version", "error_message": "Model loading failed: cannot import name '_validate_images_text_input_order' from 'transformers.processing_utils' (/opt/homebrew/Caskroom/miniconda/base/envs/mlx-vlm/lib/python3.13/site-packages/transformers/processing_utils.py)", "quality_issues": null, "metrics": {}}
{"model": "mlx-community/Kimi-VL-A3B-Thinking-8bit", "success": false, "error_stage": "Lib Version", "error_message": "Model loading failed: cannot import name '_validate_images_text_input_order' from 'transformers.processing_utils' (/opt/homebrew/Caskroom/miniconda/base/envs/mlx-vlm/lib/python3.13/site-packages/transformers/processing_utils.py)", "quality_issues": null, "metrics": {}}
{"model": "mlx-community/LFM2-VL-1.6B-8bit", "success": true, "error_stage": null, "error_message": null, "quality_issues": null, "metrics": {"prompt_tokens": 2029, "generation_tokens": 141, "generation_tps": 285.6111722699417, "peak_memory_gb": 52.703355696}}
{"model": "mlx-community/Llama-3.2-11B-Vision-Instruct-8bit", "success": true, "error_stage": null, "error_message": null, "quality_issues": "context-ignored", "metrics": {"prompt_tokens": 236, "generation_tokens": 184, "generation_tps": 9.441431183636729, "peak_memory_gb": 47.842673348}}
{"model": "mlx-community/Molmo-7B-D-0924-8bit", "success": false, "error_stage": "Missing Dep", "error_message": "Model loading failed: This modeling file requires the following packages that were not found in your environment: tensorflow. Run `pip install tensorflow`", "quality_issues": null, "metrics": {}}
{"model": "mlx-community/Molmo-7B-D-0924-bf16", "success": false, "error_stage": "Missing Dep", "error_message": "Model loading failed: This modeling file requires the following packages that were not found in your environment: tensorflow. Run `pip install tensorflow`", "quality_issues": null, "metrics": {}}
{"model": "mlx-community/Phi-3.5-vision-instruct-bf16", "success": true, "error_stage": null, "error_message": null, "quality_issues": null, "metrics": {"prompt_tokens": 1042, "generation_tokens": 145, "generation_tps": 11.216745673002583, "peak_memory_gb": 68.981997268}}
{"model": "mlx-community/Qwen2-VL-2B-Instruct-4bit", "success": false, "error_stage": "OOM", "error_message": "Model runtime error during generation for mlx-community/Qwen2-VL-2B-Instruct-4bit: [metal::malloc] Attempting to allocate 135383101952 bytes which is greater than the maximum allowed buffer size of 86586540032 bytes.", "quality_issues": null, "metrics": {}}
{"model": "mlx-community/Qwen3-VL-2B-Thinking-bf16", "success": true, "error_stage": null, "error_message": null, "quality_issues": null, "metrics": {"prompt_tokens": 16505, "generation_tokens": 500, "generation_tps": 71.58060992226473, "peak_memory_gb": 54.448929346}}
{"model": "mlx-community/SmolVLM-Instruct-bf16", "success": true, "error_stage": null, "error_message": null, "quality_issues": null, "metrics": {"prompt_tokens": 1430, "generation_tokens": 9, "generation_tps": 129.40935415814917, "peak_memory_gb": 47.40156085}}
{"model": "mlx-community/SmolVLM2-2.2B-Instruct-mlx", "success": true, "error_stage": null, "error_message": null, "quality_issues": "context-ignored", "metrics": {"prompt_tokens": 1330, "generation_tokens": 29, "generation_tps": 119.93643370105757, "peak_memory_gb": 47.43199671}}
{"model": "mlx-community/deepseek-vl2-8bit", "success": true, "error_stage": null, "error_message": null, "quality_issues": "formatting", "metrics": {"prompt_tokens": 2041, "generation_tokens": 237, "generation_tps": 62.76666521971953, "peak_memory_gb": 73.689065416}}
{"model": "mlx-community/gemma-3-12b-pt-8bit", "success": false, "error_stage": "Error", "error_message": "Cannot use apply_chat_template because this processor does not have a chat template.", "quality_issues": null, "metrics": {}}
{"model": "mlx-community/gemma-3-27b-it-qat-4bit", "success": true, "error_stage": null, "error_message": null, "quality_issues": "bullets(35)", "metrics": {"prompt_tokens": 504, "generation_tokens": 331, "generation_tps": 27.590034934390935, "peak_memory_gb": 59.96299978}}
{"model": "mlx-community/gemma-3-27b-it-qat-8bit", "success": true, "error_stage": null, "error_message": null, "quality_issues": "verbose, bullets(64)", "metrics": {"prompt_tokens": 504, "generation_tokens": 500, "generation_tps": 15.226839133540976, "peak_memory_gb": 41.856472486}}
{"model": "mlx-community/gemma-3n-E4B-it-bf16", "success": true, "error_stage": null, "error_message": null, "quality_issues": null, "metrics": {"prompt_tokens": 504, "generation_tokens": 271, "generation_tps": 41.33712559510099, "peak_memory_gb": 17.772126526}}
{"model": "mlx-community/llava-v1.6-mistral-7b-8bit", "success": true, "error_stage": null, "error_message": null, "quality_issues": "context-ignored", "metrics": {"prompt_tokens": 2321, "generation_tokens": 8, "generation_tps": 49.175843598990056, "peak_memory_gb": 12.286036238}}
{"model": "mlx-community/paligemma2-10b-ft-docci-448-6bit", "success": true, "error_stage": null, "error_message": null, "quality_issues": "repetitive(phrase: \"the scene is very...\"), context-ignored", "metrics": {"prompt_tokens": 1262, "generation_tokens": 500, "generation_tps": 41.57306620719141, "peak_memory_gb": 11.252778228}}
{"model": "mlx-community/paligemma2-10b-ft-docci-448-bf16", "success": true, "error_stage": null, "error_message": null, "quality_issues": "repetitive(phrase: \"the scene is very...\"), context-ignored", "metrics": {"prompt_tokens": 1262, "generation_tokens": 500, "generation_tps": 5.036388902391887, "peak_memory_gb": 27.10053116}}
{"model": "mlx-community/paligemma2-3b-ft-docci-448-bf16", "success": true, "error_stage": null, "error_message": null, "quality_issues": "repetitive(phrase: \"the center cube has...\"), context-ignored", "metrics": {"prompt_tokens": 1262, "generation_tokens": 500, "generation_tps": 17.876881061814238, "peak_memory_gb": 11.364263944}}
{"model": "mlx-community/paligemma2-3b-pt-896-4bit", "success": true, "error_stage": null, "error_message": null, "quality_issues": "context-ignored", "metrics": {"prompt_tokens": 4334, "generation_tokens": 22, "generation_tps": 110.35442144539478, "peak_memory_gb": 8.759003428}}
{"model": "mlx-community/pixtral-12b-8bit", "success": true, "error_stage": null, "error_message": null, "quality_issues": "verbose, bullets(16)", "metrics": {"prompt_tokens": 2842, "generation_tokens": 331, "generation_tps": 34.249286465517706, "peak_memory_gb": 15.494365504}}
{"model": "mlx-community/pixtral-12b-bf16", "success": true, "error_stage": null, "error_message": null, "quality_issues": "verbose, bullets(21)", "metrics": {"prompt_tokens": 2842, "generation_tokens": 359, "generation_tps": 19.21001587717695, "peak_memory_gb": 27.302019456}}
{"model": "prince-canuma/Florence-2-large-ft", "success": true, "error_stage": null, "error_message": null, "quality_issues": "lang_mixing, formatting, context-ignored", "metrics": {"prompt_tokens": 233, "generation_tokens": 500, "generation_tps": 322.11869058968557, "peak_memory_gb": 5.14954155}}
{"model": "qnguyen3/nanoLLaVA", "success": true, "error_stage": null, "error_message": null, "quality_issues": null, "metrics": {"prompt_tokens": 249, "generation_tokens": 86, "generation_tps": 103.1631501208104, "peak_memory_gb": 4.481959052}}
