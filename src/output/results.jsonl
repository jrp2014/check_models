{"model": "HuggingFaceTB/SmolVLM-Instruct", "success": true, "error_stage": null, "error_message": null, "quality_issues": null, "metrics": {"prompt_tokens": 1430, "generation_tokens": 19, "generation_tps": 122.14162482746579, "peak_memory_gb": 5.54614324}}
{"model": "meta-llama/Llama-3.2-11B-Vision-Instruct", "success": true, "error_stage": null, "error_message": null, "quality_issues": "bullets(20)", "metrics": {"prompt_tokens": 237, "generation_tokens": 191, "generation_tps": 3.9138475910252164, "peak_memory_gb": 25.159984966}}
{"model": "microsoft/Florence-2-large-ft", "success": false, "error_stage": "Model Error", "error_message": "Model loading failed: Missing 1 parameters: \nlanguage_model.lm_head.weight.", "quality_issues": null, "metrics": {}}
{"model": "microsoft/Phi-3.5-vision-instruct", "success": true, "error_stage": null, "error_message": null, "quality_issues": "lang_mixing, hallucination", "metrics": {"prompt_tokens": 1042, "generation_tokens": 500, "generation_tps": 10.801436215126365, "peak_memory_gb": 11.505704096}}
{"model": "mlx-community/Apriel-1.5-15b-Thinker-6bit-MLX", "success": true, "error_stage": null, "error_message": null, "quality_issues": "hallucination", "metrics": {"prompt_tokens": 2933, "generation_tokens": 500, "generation_tps": 35.51188540630994, "peak_memory_gb": 14.714749122}}
{"model": "mlx-community/Idefics3-8B-Llama3-bf16", "success": true, "error_stage": null, "error_message": null, "quality_issues": "formatting", "metrics": {"prompt_tokens": 2547, "generation_tokens": 352, "generation_tps": 29.161142357436834, "peak_memory_gb": 18.591584978}}
{"model": "mlx-community/InternVL3-14B-8bit", "success": true, "error_stage": null, "error_message": null, "quality_issues": "bullets(18)", "metrics": {"prompt_tokens": 2032, "generation_tokens": 298, "generation_tps": 28.32625976880146, "peak_memory_gb": 17.922640106}}
{"model": "mlx-community/Kimi-VL-A3B-Thinking-2506-bf16", "success": false, "error_stage": "Lib Version", "error_message": "Model loading failed: cannot import name '_validate_images_text_input_order' from 'transformers.processing_utils' (/opt/homebrew/Caskroom/miniconda/base/envs/mlx-vlm/lib/python3.13/site-packages/transformers/processing_utils.py)", "quality_issues": null, "metrics": {}}
{"model": "mlx-community/Kimi-VL-A3B-Thinking-8bit", "success": false, "error_stage": "Lib Version", "error_message": "Model loading failed: cannot import name '_validate_images_text_input_order' from 'transformers.processing_utils' (/opt/homebrew/Caskroom/miniconda/base/envs/mlx-vlm/lib/python3.13/site-packages/transformers/processing_utils.py)", "quality_issues": null, "metrics": {}}
{"model": "mlx-community/LFM2-VL-1.6B-8bit", "success": true, "error_stage": null, "error_message": null, "quality_issues": null, "metrics": {"prompt_tokens": 2029, "generation_tokens": 141, "generation_tps": 284.47275551883786, "peak_memory_gb": 52.703355696}}
{"model": "mlx-community/Llama-3.2-11B-Vision-Instruct-8bit", "success": true, "error_stage": null, "error_message": null, "quality_issues": "context-ignored", "metrics": {"prompt_tokens": 236, "generation_tokens": 145, "generation_tps": 7.39539477054209, "peak_memory_gb": 47.842673348}}
{"model": "mlx-community/Molmo-7B-D-0924-8bit", "success": false, "error_stage": "Missing Dep", "error_message": "Model loading failed: This modeling file requires the following packages that were not found in your environment: tensorflow. Run `pip install tensorflow`", "quality_issues": null, "metrics": {}}
{"model": "mlx-community/Molmo-7B-D-0924-bf16", "success": false, "error_stage": "Missing Dep", "error_message": "Model loading failed: This modeling file requires the following packages that were not found in your environment: tensorflow. Run `pip install tensorflow`", "quality_issues": null, "metrics": {}}
{"model": "mlx-community/Phi-3.5-vision-instruct-bf16", "success": true, "error_stage": null, "error_message": null, "quality_issues": null, "metrics": {"prompt_tokens": 1042, "generation_tokens": 218, "generation_tps": 10.803833681096913, "peak_memory_gb": 68.981997268}}
{"model": "mlx-community/Qwen2-VL-2B-Instruct-4bit", "success": false, "error_stage": "OOM", "error_message": "Model runtime error during generation for mlx-community/Qwen2-VL-2B-Instruct-4bit: [metal::malloc] Attempting to allocate 135383101952 bytes which is greater than the maximum allowed buffer size of 86586540032 bytes.", "quality_issues": null, "metrics": {}}
{"model": "mlx-community/Qwen3-VL-2B-Thinking-bf16", "success": true, "error_stage": null, "error_message": null, "quality_issues": "verbose", "metrics": {"prompt_tokens": 16505, "generation_tokens": 500, "generation_tps": 60.221377998666675, "peak_memory_gb": 45.412064834}}
{"model": "mlx-community/SmolVLM-Instruct-bf16", "success": true, "error_stage": null, "error_message": null, "quality_issues": null, "metrics": {"prompt_tokens": 1430, "generation_tokens": 9, "generation_tps": 127.86641333685591, "peak_memory_gb": 38.364696338}}
{"model": "mlx-community/SmolVLM2-2.2B-Instruct-mlx", "success": true, "error_stage": null, "error_message": null, "quality_issues": "context-ignored", "metrics": {"prompt_tokens": 1330, "generation_tokens": 29, "generation_tps": 114.50980784351532, "peak_memory_gb": 38.395132198}}
{"model": "mlx-community/deepseek-vl2-8bit", "success": true, "error_stage": null, "error_message": null, "quality_issues": "formatting", "metrics": {"prompt_tokens": 2041, "generation_tokens": 226, "generation_tps": 62.87090530623857, "peak_memory_gb": 64.652200904}}
{"model": "mlx-community/deepseek-vl2-tiny-3bit", "success": false, "error_stage": "Error", "error_message": "Model loading failed: Operation timed out after 300.0 seconds", "quality_issues": null, "metrics": {}}
{"model": "mlx-community/gemma-3-12b-pt-8bit", "success": false, "error_stage": "Error", "error_message": "Cannot use apply_chat_template because this processor does not have a chat template.", "quality_issues": null, "metrics": {}}
{"model": "mlx-community/gemma-3-27b-it-qat-4bit", "success": true, "error_stage": null, "error_message": null, "quality_issues": "bullets(33)", "metrics": {"prompt_tokens": 504, "generation_tokens": 322, "generation_tps": 27.903786632359665, "peak_memory_gb": 50.926135268}}
{"model": "mlx-community/gemma-3-27b-it-qat-8bit", "success": true, "error_stage": null, "error_message": null, "quality_issues": "bullets(26)", "metrics": {"prompt_tokens": 504, "generation_tokens": 349, "generation_tps": 15.327514845260064, "peak_memory_gb": 32.819607974}}
{"model": "mlx-community/gemma-3n-E4B-it-bf16", "success": true, "error_stage": null, "error_message": null, "quality_issues": null, "metrics": {"prompt_tokens": 504, "generation_tokens": 191, "generation_tps": 41.49365687297245, "peak_memory_gb": 17.772126526}}
{"model": "mlx-community/llava-v1.6-mistral-7b-8bit", "success": true, "error_stage": null, "error_message": null, "quality_issues": "context-ignored", "metrics": {"prompt_tokens": 2321, "generation_tokens": 8, "generation_tps": 47.78232779504623, "peak_memory_gb": 12.286036238}}
{"model": "mlx-community/paligemma2-10b-ft-docci-448-6bit", "success": true, "error_stage": null, "error_message": null, "quality_issues": "context-ignored", "metrics": {"prompt_tokens": 1262, "generation_tokens": 159, "generation_tps": 40.55034856547733, "peak_memory_gb": 11.252778228}}
{"model": "mlx-community/paligemma2-10b-ft-docci-448-bf16", "success": true, "error_stage": null, "error_message": null, "quality_issues": "context-ignored", "metrics": {"prompt_tokens": 1262, "generation_tokens": 174, "generation_tps": 4.826330930446838, "peak_memory_gb": 26.918037976}}
{"model": "mlx-community/paligemma2-3b-ft-docci-448-bf16", "success": true, "error_stage": null, "error_message": null, "quality_issues": "repetitive(phrase: \"the right side of...\"), context-ignored", "metrics": {"prompt_tokens": 1262, "generation_tokens": 500, "generation_tps": 12.960317300190301, "peak_memory_gb": 11.364264456}}
{"model": "mlx-community/paligemma2-3b-pt-896-4bit", "success": true, "error_stage": null, "error_message": null, "quality_issues": "context-ignored", "metrics": {"prompt_tokens": 4334, "generation_tokens": 14, "generation_tps": 6.7425124410297395, "peak_memory_gb": 8.759003428}}
{"model": "mlx-community/pixtral-12b-8bit", "success": true, "error_stage": null, "error_message": null, "quality_issues": "verbose, bullets(16)", "metrics": {"prompt_tokens": 2842, "generation_tokens": 321, "generation_tps": 32.92787651396891, "peak_memory_gb": 15.412871488}}
{"model": "mlx-community/pixtral-12b-bf16", "success": true, "error_stage": null, "error_message": null, "quality_issues": "bullets(18)", "metrics": {"prompt_tokens": 2842, "generation_tokens": 283, "generation_tps": 18.900585026526272, "peak_memory_gb": 27.302019456}}
{"model": "prince-canuma/Florence-2-large-ft", "success": true, "error_stage": null, "error_message": null, "quality_issues": "lang_mixing, formatting, context-ignored", "metrics": {"prompt_tokens": 233, "generation_tokens": 500, "generation_tps": 318.12812555634144, "peak_memory_gb": 5.14954155}}
{"model": "qnguyen3/nanoLLaVA", "success": true, "error_stage": null, "error_message": null, "quality_issues": null, "metrics": {"prompt_tokens": 249, "generation_tokens": 81, "generation_tps": 103.03992692248897, "peak_memory_gb": 4.468319136}}
